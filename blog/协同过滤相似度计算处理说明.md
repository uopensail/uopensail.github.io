# 协同过滤相似度计算处理说明

## 一、环境准备

1. **Python环境**
   
   - 版本要求：Python ≥3.8
   
   - 推荐使用虚拟环境：
     
     ```Python
     python -m venv cf_env
     source cf_env/bin/activate  # Linux/Mac
     cf_env\Scripts\activate     # Windows
     ```

2. **依赖安装**
   
   ```shell
   pip install tomli multiprocess 
   # 仅Python<3.11需要安装tomli
   ```

---

## 二、配置文件准备

1. **创建`config.toml`文件**
   
   ```toml
   [io]
   input_path = "input/interactions.csv"  # 原始交互数据路径
   output_base = "output"                # 输出目录根路径
   item_ids_path = "input/valid_items.txt" # 有效物品ID列表
   keep_intermediate = false             # 是否保留中间文件
   
   [params]
   min_items = 2        # 最小交互物品数
   max_items = 100      # 最大交互物品数
   top_k = 20           # 生成推荐数量
   num_workers = 8      # 并行进程数
   min_cooccurrence = 1 # 共现最低次数
   min_norm = 9         # 物品最少出现次数
   ```

2. **输入文件结构**
   
   - **交互数据文件**(interactions.txt)：
     
     ```text
     itemA itemC itemD
     itemB itemE
     itemA itemB itemC
     ```
   
   - **有效物品列表**(valid_items.txt)：
     
     ```text
     itemA
     itemB
     itemC
     ```

---

## 三、执行流程

```shell
# 运行程序
python cf_similarity.py config.toml
```

#### **处理阶段说明**

1. **阶段1：数据分片**
   
   - 输入：原始交互数据文件
   - 输出：`output/split/0.txt`, `output/split/1.txt`, ...
   - 特点：流式处理，内存占用恒定

2. **阶段2：并行共现统计**
   
   - 每个工作进程处理一个分片文件
   - 生成中间文件：
     - 共现计数：`output/intermediate/*/pairs.txt`
     - 物品计数：`output/intermediate/*/norms.txt`

3. **阶段3：结果聚合**
   
   - 输出合并文件：
     - `output/merged_pairs.txt` 格式：`item1#item2\tcount`
     - `output/merged_norms.txt` 格式：`item\tcount`

4. **阶段4：相似度计算**
   
   - 计算余弦相似度：`sim(i,j) = cooccur(i,j) / sqrt(count(i)*count(j))`
   - 生成内存数据结构：`{item: [(neighbor, score), ...]}`

5. **阶段5：推荐生成**
   
   - 最终输出文件：`output/recommendations.txt`
   
   - 格式示例：
     
     ```text
     itemA    itemC:0.82,itemD:0.76,itemB:0.68
     itemB    itemE:0.91,itemA:0.68,itemC:0.65
     ```

---

## 四、输出文件说明

| 文件路径                         | 内容       | 示例                       |
| ---------------------------- | -------- | ------------------------ |
| `output/recommendations.txt` | 最终推荐结果   | `item\t邻居1:分数,邻居2:分数...` |
| `output/merged_pairs.txt`    | 合并后的共现次数 | `itemA#itemB\t15`        |
| `output/merged_norms.txt`    | 物品出现总次数  | `itemA\t42`              |

---

## 五、清理机制

1. **自动清理策略**（默认开启）
   
   - 删除中间分片文件(`split/`)
   - 清除处理中间目录(`intermediate/`)
   - 移除合并的中间文件(`merged_*`)

2. **保留中间文件** 配置文件中设置：`keep_intermediate = true`

---

### **六、性能调优建议**

1. **并行度调整**
   
   - 根据CPU核心数设置`num_workers`
   - 建议：CPU逻辑核心数 × 0.75

2. **内存优化**
   
   - 处理超大数据时（>1亿条记录）：
     
     ```toml
     [params]
     min_cooccurrence = 2  # 提高共现阈值
     min_norm = 10         # 过滤低频物品
     ```

3. **分布式扩展**
   
   - 将分片文件分布到不同机器处理
   - 集中合并结果时使用分布式文件系统

---

## 七、异常处理指南

| 异常现象   | 解决方案                             |
| ------ | -------------------------------- |
| 文件权限错误 | 检查输出目录可写权限                       |
| 内存不足   | 降低`num_workers`或增加过滤阈值           |
| 无效物品ID | 检查输入数据中的非空行和合法字符                 |
| 共现矩阵为空 | 检查`min_items/max_items`是否过滤了所有记录 |
